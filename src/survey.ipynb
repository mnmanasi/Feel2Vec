{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AcCneNZ1_SKe"},"outputs":[],"source":["import pandas as pd\n","import ast\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tExQYvwc_SKf"},"outputs":[],"source":["# get all survey data and format\n","survey_data = {\n","    'song_id' : [6636486] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.15, 0.10, 0.20, 0.05, 0.10, 0.05, 0.20, 0.15, 0.05, 0.10],\n","    'Joy': [0.10, 0.05, 0.05, 0.05, 0.15, 0.10, 0.05, 0.05, 0.10, 0.10],\n","    'Surprise': [0.05, 0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05, 0.10, 0.10],\n","    'Anger': [0.30, 0.40, 0.25, 0.35, 0.25, 0.30, 0.25, 0.35, 0.30, 0.30],\n","    'Disgust': [0.10, 0.05, 0.10, 0.15, 0.05, 0.10, 0.10, 0.05, 0.05, 0.05],\n","    'Fear': [0.15, 0.10, 0.15, 0.10, 0.20, 0.15, 0.10, 0.10, 0.10, 0.10],\n","    'Sadness': [0.10, 0.20, 0.10, 0.10, 0.10, 0.15, 0.15, 0.15, 0.20, 0.15],\n","    'Trust': [0.05, 0.05, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10]\n","}\n","survey_1 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [5955393] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.10, 0.10, 0.15, 0.05, 0.10, 0.05, 0.20, 0.05, 0.10, 0.15],\n","    'Joy': [0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05, 0.10, 0.05, 0.05],\n","    'Surprise': [0.05, 0.05, 0.10, 0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05],\n","    'Anger': [0.25, 0.25, 0.30, 0.35, 0.30, 0.35, 0.25, 0.30, 0.30, 0.30],\n","    'Disgust': [0.10, 0.05, 0.10, 0.15, 0.05, 0.10, 0.10, 0.05, 0.05, 0.05],\n","    'Fear': [0.20, 0.15, 0.15, 0.20, 0.25, 0.20, 0.20, 0.15, 0.20, 0.25],\n","    'Sadness': [0.20, 0.30, 0.25, 0.15, 0.20, 0.15, 0.25, 0.25, 0.25, 0.20],\n","    'Trust': [0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n","}\n","survey_2 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [4191823] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.25, 0.30, 0.35, 0.30, 0.25, 0.20, 0.30, 0.35, 0.30, 0.25],\n","    'Joy': [0.15, 0.10, 0.15, 0.10, 0.10, 0.15, 0.10, 0.10, 0.15, 0.10],\n","    'Surprise': [0.20, 0.15, 0.20, 0.20, 0.15, 0.20, 0.25, 0.20, 0.15, 0.20],\n","    'Anger': [0.30, 0.35, 0.40, 0.35, 0.40, 0.35, 0.30, 0.40, 0.35, 0.30],\n","    'Disgust': [0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n","    'Fear': [0.15, 0.20, 0.15, 0.20, 0.15, 0.15, 0.20, 0.15, 0.20, 0.15],\n","    'Sadness': [0.05, 0.10, 0.05, 0.05, 0.10, 0.05, 0.05, 0.10, 0.05, 0.05],\n","    'Trust': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n","}\n","survey_3 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [1062758] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.45, 0.40, 0.50, 0.55, 0.50, 0.45, 0.40, 0.50, 0.45, 0.50],\n","    'Joy': [0.35, 0.40, 0.35, 0.30, 0.35, 0.40, 0.40, 0.35, 0.35, 0.30],\n","    'Surprise': [0.05, 0.10, 0.05, 0.05, 0.05, 0.10, 0.05, 0.05, 0.10, 0.05],\n","    'Anger': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n","    'Disgust': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n","    'Fear': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n","    'Sadness': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n","    'Trust': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n","}\n","survey_4 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [7402191] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.55, 0.60, 0.50, 0.45, 0.50, 0.55, 0.60, 0.50, 0.45, 0.50],\n","    'Joy': [0.25, 0.20, 0.25, 0.30, 0.25, 0.20, 0.20, 0.25, 0.30, 0.25],\n","    'Surprise': [0.15, 0.10, 0.15, 0.15, 0.10, 0.15, 0.10, 0.15, 0.15, 0.10],\n","    'Anger': [0.60, 0.55, 0.60, 0.65, 0.60, 0.55, 0.55, 0.60, 0.65, 0.60],\n","    'Disgust': [0.50, 0.45, 0.50, 0.55, 0.50, 0.45, 0.45, 0.50, 0.55, 0.50],\n","    'Fear': [0.35, 0.30, 0.35, 0.40, 0.35, 0.30, 0.30, 0.35, 0.40, 0.35],\n","    'Sadness': [0.30, 0.25, 0.30, 0.35, 0.30, 0.25, 0.25, 0.30, 0.35, 0.30],\n","    'Trust': [0.20, 0.15, 0.20, 0.25, 0.20, 0.15, 0.15, 0.20, 0.25, 0.20]\n","}\n","survey_5 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [6047243] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.25, 0.20, 0.15, 0.25, 0.20, 0.30, 0.20, 0.25, 0.30, 0.20],\n","    'Joy': [0.10, 0.05, 0.15, 0.10, 0.05, 0.10, 0.05, 0.10, 0.05, 0.05],\n","    'Surprise': [0.05, 0.10, 0.05, 0.05, 0.10, 0.05, 0.05, 0.10, 0.05, 0.05],\n","    'Anger': [0.50, 0.55, 0.50, 0.55, 0.60, 0.55, 0.50, 0.55, 0.60, 0.55],\n","    'Disgust': [0.35, 0.40, 0.35, 0.40, 0.45, 0.40, 0.35, 0.40, 0.45, 0.40],\n","    'Fear': [0.60, 0.55, 0.60, 0.65, 0.60, 0.65, 0.60, 0.65, 0.60, 0.65],\n","    'Sadness': [0.70, 0.75, 0.70, 0.75, 0.80, 0.75, 0.70, 0.75, 0.80, 0.75],\n","    'Trust': [0.15, 0.10, 0.15, 0.10, 0.05, 0.10, 0.15, 0.10, 0.05, 0.10]\n","}\n","survey_6 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [4313071] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.25, 0.20, 0.30, 0.20, 0.25, 0.30, 0.25, 0.20, 0.15, 0.25],\n","    'Joy': [0.20, 0.30, 0.25, 0.30, 0.25, 0.20, 0.15, 0.20, 0.30, 0.25],\n","    'Surprise': [0.10, 0.10, 0.05, 0.10, 0.10, 0.10, 0.05, 0.10, 0.10, 0.05],\n","    'Anger': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.10, 0.05, 0.05, 0.05],\n","    'Disgust': [0.05, 0.05, 0.05, 0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05],\n","    'Fear': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.10, 0.05, 0.05, 0.05],\n","    'Sadness': [0.20, 0.20, 0.20, 0.15, 0.20, 0.15, 0.15, 0.20, 0.15, 0.15],\n","    'Trust': [0.10, 0.05, 0.05, 0.05, 0.10, 0.05, 0.10, 0.05, 0.10, 0.10]\n","}\n","survey_7 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [6850734] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.20, 0.25, 0.20, 0.30, 0.25, 0.20, 0.15, 0.25, 0.20, 0.20],\n","    'Joy': [0.15, 0.10, 0.15, 0.20, 0.10, 0.15, 0.20, 0.15, 0.10, 0.15],\n","    'Surprise': [0.10, 0.15, 0.10, 0.05, 0.15, 0.10, 0.10, 0.10, 0.15, 0.10],\n","    'Anger': [0.05, 0.05, 0.05, 0.10, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05],\n","    'Disgust': [0.05, 0.10, 0.05, 0.05, 0.05, 0.05, 0.10, 0.05, 0.10, 0.05],\n","    'Fear': [0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.10],\n","    'Sadness': [0.20, 0.15, 0.20, 0.15, 0.20, 0.15, 0.20, 0.20, 0.20, 0.15],\n","    'Trust': [0.20, 0.15, 0.15, 0.10, 0.15, 0.15, 0.15, 0.15, 0.15, 0.20]\n","}\n","survey_8 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [6736901] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n","    'Joy': [0.01, 0.00, 0.00, 0.01, 0.00, 0.01, 0.00, 0.00, 0.01, 0.00],\n","    'Surprise': [0.05, 0.10, 0.05, 0.00, 0.00, 0.05, 0.05, 0.10, 0.05, 0.05],\n","    'Anger': [0.10, 0.15, 0.20, 0.15, 0.10, 0.10, 0.15, 0.15, 0.10, 0.15],\n","    'Disgust': [0.20, 0.25, 0.20, 0.30, 0.20, 0.25, 0.20, 0.20, 0.25, 0.20],\n","    'Fear': [0.25, 0.20, 0.25, 0.25, 0.30, 0.30, 0.25, 0.20, 0.25, 0.25],\n","    'Sadness': [0.30, 0.25, 0.25, 0.25, 0.30, 0.25, 0.30, 0.25, 0.25, 0.25],\n","    'Trust': [0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.05, 0.00, 0.00]\n","}\n","survey_9 = pd.DataFrame(survey_data)\n","\n","survey_data = {\n","    'song_id': [6184434] * 10,\n","    'Participant': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    'Anticipation': [0.10, 0.15, 0.10, 0.10, 0.15, 0.10, 0.15, 0.10, 0.15, 0.10],\n","    'Joy': [0.05, 0.00, 0.05, 0.00, 0.00, 0.05, 0.00, 0.05, 0.00, 0.05],\n","    'Surprise': [0.10, 0.05, 0.05, 0.10, 0.10, 0.05, 0.05, 0.10, 0.05, 0.05],\n","    'Anger': [0.20, 0.25, 0.30, 0.20, 0.25, 0.20, 0.25, 0.25, 0.20, 0.20],\n","    'Disgust': [0.05, 0.05, 0.05, 0.05, 0.05, 0.10, 0.05, 0.05, 0.05, 0.05],\n","    'Fear': [0.25, 0.20, 0.25, 0.30, 0.25, 0.25, 0.20, 0.20, 0.25, 0.25],\n","    'Sadness': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25],\n","    'Trust': [0.00, 0.05, 0.00, 0.10, 0.10, 0.05, 0.05, 0.05, 0.10, 0.05]\n","}\n","survey_10 = pd.DataFrame(survey_data)\n","\n","\n","\n","survey_df = pd.concat([survey_1, survey_2, survey_3, survey_4, survey_5, survey_6, survey_7, survey_8, survey_9, survey_10], ignore_index=True)\n","\n","aggregated_df = survey_df.drop('Participant', axis=1).groupby('song_id').mean().reset_index()\n","\n","# Normalize the distributions so that they sum to 1\n","emotions = ['Anticipation', 'Joy', 'Surprise', 'Anger', 'Disgust', 'Fear', 'Sadness', 'Trust']\n","aggregated_df[emotions] = aggregated_df[emotions].div(aggregated_df[emotions].sum(axis=1), axis=0)\n","\n","survey_df = aggregated_df.sort_values(by='song_id').reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSTDilaL_SKg"},"outputs":[],"source":["# get all emotion data and format\n","list_of_song_ids = survey_df['song_id'].unique().tolist()\n","\n","emotion_df = pd.read_csv('emotion_assigned_songs.csv')\n","emotion_df = emotion_df[emotion_df['song_id'].isin(list_of_song_ids)].reset_index()\n","\n","def convert_defaultdict_string(s):\n","    dict_string = s.replace(\"defaultdict(<class 'int'>, \", \"\").strip(\"()\")\n","    return ast.literal_eval(dict_string)\n","\n","emotion_df['emotion_distribution'] = emotion_df['emotion_distribution'].apply(convert_defaultdict_string)\n","\n","emotions = ['anticipation', 'joy', 'surprise', 'anger', 'disgust', 'fear', 'sadness', 'trust']\n","\n","result_df = pd.DataFrame()\n","result_df['song_id'] = emotion_df['song_id']\n","for emotion in emotions:\n","    result_df[emotion.capitalize()] = emotion_df['emotion_distribution'].apply(lambda x: x.get(emotion, 0))\n","\n","emotion_df = result_df.sort_values(by='song_id').reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mho35FuI_SKh","outputId":"42da395a-c31b-404e-f350-0214755ce9ff"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>song_id</th>\n","      <th>KL_Divergence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1062758.0</td>\n","      <td>0.946462</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4191823.0</td>\n","      <td>0.155166</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4313071.0</td>\n","      <td>0.422628</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5955393.0</td>\n","      <td>0.292585</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6047243.0</td>\n","      <td>0.492483</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6184434.0</td>\n","      <td>0.228473</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6636486.0</td>\n","      <td>0.188995</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6736901.0</td>\n","      <td>0.379533</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>6850734.0</td>\n","      <td>0.936562</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>7402191.0</td>\n","      <td>0.327137</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     song_id  KL_Divergence\n","0  1062758.0       0.946462\n","1  4191823.0       0.155166\n","2  4313071.0       0.422628\n","3  5955393.0       0.292585\n","4  6047243.0       0.492483\n","5  6184434.0       0.228473\n","6  6636486.0       0.188995\n","7  6736901.0       0.379533\n","8  6850734.0       0.936562\n","9  7402191.0       0.327137"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["#calculate KL Divergence\n","def kl_divergence(p, q):\n","    # Avoid division by zero and log(0)\n","    p = np.array(p)\n","    q = np.array(q)\n","    p = p + 1e-10  # Add small value to avoid log(0)\n","    q = q + 1e-10  # Add small value to avoid division by zero\n","    return np.sum(p * np.log(p / q))\n","\n","results = []\n","for _, row in survey_df.iterrows():\n","    song_id = row['song_id']\n","    true_dist = row[1:].values\n","    predicted_dist = emotion_df[emotion_df['song_id'] == song_id].iloc[0, 1:].values\n","    kl_div = kl_divergence(true_dist, predicted_dist)\n","    results.append({'song_id': song_id, 'KL_Divergence': kl_div})\n","\n","kl_results_df = pd.DataFrame(results)\n","\n","kl_results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuQR0_a2_SKh","outputId":"b2a575c3-deb9-45e2-f4ae-1cb89223ae08"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>song_id</th>\n","      <th>self_similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1062758</td>\n","      <td>0.126628</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4191823</td>\n","      <td>0.969375</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4313071</td>\n","      <td>0.986858</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5955393</td>\n","      <td>0.963733</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6047243</td>\n","      <td>0.996586</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6184434</td>\n","      <td>0.998435</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6636486</td>\n","      <td>0.054223</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6736901</td>\n","      <td>0.999222</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>6850734</td>\n","      <td>0.998101</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>7402191</td>\n","      <td>0.997302</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   song_id  self_similarity\n","0  1062758         0.126628\n","1  4191823         0.969375\n","2  4313071         0.986858\n","3  5955393         0.963733\n","4  6047243         0.996586\n","5  6184434         0.998435\n","6  6636486         0.054223\n","7  6736901         0.999222\n","8  6850734         0.998101\n","9  7402191         0.997302"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["#calculate Cosine Similarity\n","emotion_features = emotion_df.drop(columns='song_id')\n","survey_features = survey_df.drop(columns='song_id')\n","\n","similarity_matrix = cosine_similarity(emotion_features, survey_features)\n","\n","similarity_df = pd.DataFrame(similarity_matrix, index=emotion_df['song_id'], columns=survey_df['song_id'])\n","\n","self_similarity = similarity_df.values.diagonal()\n","\n","self_similarity_df = pd.DataFrame({\n","    'song_id': emotion_df['song_id'],\n","    'self_similarity': self_similarity\n","})\n","\n","self_similarity_df"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
